{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "This notebook demonstrates how to generate samples using MUGL pretrained model and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipyvolume as ipv\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from model.model import *\n",
    "from rotation.rotation import rot6d_to_rotmat, batch_rigid_transform\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMPL = np.load(\"./files/SMPLX_NEUTRAL.npz\")\n",
    "# parent_array = SMPL['kintree_table'][0][:24]\n",
    "parent_array = np.array([-1, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 12, 13, 14, 16, 17, 18, 19, 15, 15])\n",
    "skeleton = np.load('./files/skeleton.npy')\n",
    "\n",
    "latent_dim = 352\n",
    "device = torch.device('cuda:0')\n",
    "num_class = 120\n",
    "# print(list(parent_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(skeleton_motion1, skeleton_motion2, single=False, save_gif=False, save_name = \"example\"):\n",
    "    '''\n",
    "        Function to plot generated samples\n",
    "        Input:\n",
    "            skeleton_motion1: (64, 24, 3) skeleton of the person 1\n",
    "            skeleton_motion2: (64, 24, 3) skeleton of the person 2\n",
    "            single: True if it's a sinle person class else False\n",
    "            save_gif: saves the sequence in a gif file\n",
    "            save_name: Name pof the gif file\n",
    "    '''\n",
    "    fig = ipv.figure(width=600,height=600)\n",
    "    skeleton_motion1[:,:,1] *= -1\n",
    "    skeleton_motion1[:,:,2] *= -1\n",
    "    \n",
    "    skeleton_motion2[:,:,1] *= -1\n",
    "    skeleton_motion2[:,:,2] *= -1\n",
    "    \n",
    "    s = ipv.scatter(skeleton_motion1[:,:,0],skeleton_motion1[:,:,1],skeleton_motion1[:,:,2],size=2.5,color='indigo',marker='sphere')\n",
    "    if not single:\n",
    "        s1 = ipv.scatter(skeleton_motion2[:,:,0],skeleton_motion2[:,:,1],skeleton_motion2[:,:,2],size=2.5,color='red',marker='sphere')\n",
    "        anim_list = [s,s1]\n",
    "    else:\n",
    "        anim_list = [s]\n",
    "    \n",
    "    for i,p in enumerate(parent_array): # Run loop for each bone\n",
    "        if p == -1:\n",
    "            continue\n",
    "        b = ipv.plot(np.array([skeleton_motion1[:,i,0],skeleton_motion1[:,p,0]]).T,np.array([skeleton_motion1[:,i,1],skeleton_motion1[:,p,1]]).T,np.array([skeleton_motion1[:,i,2],skeleton_motion1[:,p,2]]).T ,size=10, color='darkviolet')\n",
    "        anim_list.append(b)\n",
    "        if not single:\n",
    "            b1 = ipv.plot(np.array([skeleton_motion2[:,i,0],skeleton_motion2[:,p,0]]).T,np.array([skeleton_motion2[:,i,1],skeleton_motion2[:,p,1]]).T,np.array([skeleton_motion2[:,i,2],skeleton_motion2[:,p,2]]).T ,size=10, color='orange')\n",
    "            anim_list.append(b1)\n",
    "    \n",
    "    \n",
    "#     ipv.plot_surface(x,y,z, color='red')\n",
    "#     ipv.plot_wireframe(x,y,z,color='tan')\n",
    "    ipv.animation_control(anim_list, interval=0.01)\n",
    "    ipv.style.background_color('white')\n",
    "    ipv.style.box_off()\n",
    "    ipv.style.axes_off()\n",
    "    ipv.show()\n",
    "    \n",
    "    if save_gif:\n",
    "        def slide(figure, framenr, fraction):\n",
    "            for a in anim_list:\n",
    "                if a.sequence_index == skeleton_motion1.shape[0]:\n",
    "                    a.sequence_index = 0\n",
    "                a.sequence_index += 1        \n",
    "        ipv.movie(save_name + '.gif', slide, fps=5, frames=skeleton_motion1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fkt(x, mean_pose):\n",
    "    '''\n",
    "        This function takes joint rotatioins and t-pose and performs forward kinematics.\n",
    "        input:\n",
    "            x: (batch_size, 64, 24, 6)\n",
    "            mean_pose: (24, 6)\n",
    "        Returns:\n",
    "            x: (batch_size, 64, 24, 3) 3-D skeleton\n",
    "    '''\n",
    "    # forward kinematics\n",
    "    rotmat = rot6d_to_rotmat(x)\n",
    "    # same mean pose across timesteps\n",
    "    mean_pose = torch.tensor(mean_pose.reshape((1, -1)))\n",
    "    mean_pose = mean_pose.expand((x.shape[0], x.shape[1], 72))\n",
    "    mean_pose = mean_pose[:,:,:].reshape((x.shape[0]*x.shape[1],-1,3))\n",
    "    rotmat = rotmat.reshape((x.shape[0]*x.shape[1],-1, 3, 3))\n",
    "    pred = batch_rigid_transform(rotmat.float(),mean_pose.to(device).float(),parent_array)\n",
    "    x = pred.reshape((x.shape[0], x.shape[1], -1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, class_label, num_sample=10):\n",
    "    '''\n",
    "        Function to generate sample using pretrained model\n",
    "        Input: \n",
    "            model: saved model file\n",
    "            class_label: class index\n",
    "            num_sample: number of samples to be generated\n",
    "        Return:\n",
    "            pred_3d1: 3D skeleton of the first person\n",
    "            pred_3d2: 3D skeleton of the second person\n",
    "            seq_pred: predicted sequence length\n",
    "    '''\n",
    "    model.eval()\n",
    "    # z = torch.randn(6, latent_dim).to(device).float()\n",
    "    rot = np.load('./files/viewpoint.npy')\n",
    "    # y = np.repeat(np.arange(3),2)\n",
    "    # y = np.arange(num_class)\n",
    "    y = np.repeat(class_label,num_sample)\n",
    "    rot = np.repeat(rot[0:1], num_sample, axis=0)\n",
    "#     print(rot.shape)\n",
    "    # rot = torch.tensor(rot[:,0,:]).to(device).float()\n",
    "    rot = rot[:,0,:].reshape((rot.shape[0],48,6))\n",
    "    rot = rot[:,0,:]\n",
    "    rot = torch.tensor(rot).to(device).float()\n",
    "\n",
    "    label = np.zeros((y.shape[0], num_class))\n",
    "    label[np.arange(y.shape[0]), y] = 1\n",
    "    label = torch.tensor(label).to(device).float()\n",
    "    with torch.no_grad():\n",
    "        m, v = model.gaussian_parameters(model.z_pre.squeeze(0), dim=0)\n",
    "        idx = torch.distributions.categorical.Categorical(model.pi).sample((label.shape[0],))\n",
    "        m, v = m[idx], v[idx]\n",
    "        z = model.sample_gaussian(m, v)\n",
    "        \n",
    "        z = torch.cat((z,label,rot), dim=1)\n",
    "        z = model.latent2hidden(z)\n",
    "        seq_pred = model.seq_decoder(z).cpu().data.numpy()\n",
    "        z = z.reshape((z.shape[0], 4, -1))\n",
    "        pred = model.decoder_net(z)\n",
    "        root_pred = model.root_traj(z).unsqueeze(2)\n",
    "        pred_3d1 = fkt(pred[:,:,:144].contiguous(), skeleton)\n",
    "        pred_3d2 = fkt(pred[:,:,144:].contiguous(), skeleton)\n",
    "        # pred_3d = fkt(pred, skeleton).cpu().data.numpy()\n",
    "        pred_3d1 = pred_3d1.reshape((pred_3d1.shape[0], pred_3d1.shape[1], 24,-1)).cpu().data.numpy()\n",
    "        pred_3d2 = pred_3d2.reshape((pred_3d2.shape[0], pred_3d2.shape[1], 24,-1)).cpu().data.numpy()\n",
    "        root_pred = root_pred.cpu().data.numpy()\n",
    "        pred_3d1 = pred_3d1 + root_pred[:,:,:,:3]\n",
    "        pred_3d2 = pred_3d2 + root_pred[:,:,:,3:]\n",
    "\n",
    "        return pred_3d1, pred_3d2, seq_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded..\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model = Model(120, latent_dim).to(device)\n",
    "model.load_state_dict(torch.load('./checkpoints/' + 'model_199.pt', map_location=torch.device('cpu')))\n",
    "print('model loaded..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class label : class index can be found in utils/class_index.txt\n",
    "class_label = 58\n",
    "p1, p2, seq = infer(model, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = seq[:,:,0]\n",
    "pred_len = pred_len <= 0.975\n",
    "pred_len = np.sum(pred_len, axis=1)\n",
    "# print(pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5df5160392f41e7baca6747bd05beef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(animation=0.01, camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "plot(p1[idx,:pred_len[idx],:,:], p2[idx,:pred_len[idx],:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
